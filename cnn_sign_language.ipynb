{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Convolutional neural network for sign language alphabet\n",
    "\n",
    "### Euler Gomes da Rocha"
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Ambient preparation",
   "id": "1d5a6cffd0487f7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T14:49:46.172017900Z",
     "start_time": "2025-12-21T14:49:46.140907100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T14:49:46.185850800Z",
     "start_time": "2025-12-21T14:49:46.175016400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"dataset\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)"
   ],
   "id": "8a5283695f9ac189",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.1 Packages import",
   "id": "aec86fcc16be41b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T14:49:46.201954300Z",
     "start_time": "2025-12-21T14:49:46.186851300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tabulate import tabulate\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "import progressbar\n",
    "\n",
    "import pygame\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import pydot as pyd\n",
    "from tensorflow.keras.utils import plot_model, model_to_dot\n",
    "\n",
    "tensorflow.keras.utils.pydot = pyd"
   ],
   "id": "b9f7c63d8c48ce37",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.2 Check versions",
   "id": "339a29616dc25c87"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T14:49:46.218952200Z",
     "start_time": "2025-12-21T14:49:46.202952500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "print(f\"Matplotlib version: {matplotlib.__version__}\")\n",
    "\n",
    "print(f\"Seaborn version: {sns.__version__}\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")"
   ],
   "id": "9ffe7e0933fff85f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.9.25 (main, Nov  3 2025, 22:44:01) [MSC v.1929 64 bit (AMD64)]\n",
      "NumPy version: 1.26.4\n",
      "TensorFlow version: 2.10.1\n",
      "Pandas version: 2.3.3\n",
      "Matplotlib version: 3.9.4\n",
      "Seaborn version: 0.13.2\n",
      "OpenCV version: 4.9.0\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.3 Check GPU",
   "id": "ac6f54637e1ab994"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T14:49:46.240086200Z",
     "start_time": "2025-12-21T14:49:46.219952100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"TensorFlow encontrou GPUs: {len(gpus) > 0}\")\n",
    "print(f\"Dispositivos GPU TensorFlow: {gpus}\")"
   ],
   "id": "cc6adddea9d0f685",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow encontrou GPUs: True\n",
      "Dispositivos GPU TensorFlow: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Experiment parameters",
   "id": "90308ee99cb5f8f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.1. Capture configuration",
   "id": "df56c0427bfa4436"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T14:49:46.250089700Z",
     "start_time": "2025-12-21T14:49:46.240086200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "capture_time = 10  #capture time em seconds\n",
    "capture_count = 50  #photo amount per class\n",
    "img_size = 128  #photo size\n",
    "box_size = 400  #capture boz size in pixels\n",
    "\n",
    "new_capture = True  #performs a new photo capture if is equal True"
   ],
   "id": "dc87e971a73cbd40",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.2. Model and training configuration",
   "id": "13b3b2ad1bd48812"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T14:49:46.266060800Z",
     "start_time": "2025-12-21T14:49:46.250089700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "new_model = True  #generate a new model\n",
    "augmentation_exec = True  #perform data augmentation if is equal True\n",
    "normalization_exec = True  #perform data nomatlization if is equal True\n",
    "\n",
    "confidence_threshold = 0.6  #confidence to classify to none\n",
    "\n",
    "model_name = 'cnn_sign_language'\n",
    "\n",
    "class_name = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U','V', 'W', 'X', 'Y', 'Z']  #model classes\n",
    "num_classes = len(class_name)"
   ],
   "id": "6018e9ff9329918a",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Image capture",
   "id": "1270ca7075cf8276"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.1. Auxiliary capture functions",
   "id": "cf4feb998599b6a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T14:49:46.285328600Z",
     "start_time": "2025-12-21T14:49:46.266740500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_capture_folder(base_path='dataset'):\n",
    "    folder_path = os.path.join(base_path, 'capture')  #folder path to photo capture\n",
    "\n",
    "    #if folder exists, delete and recreate\n",
    "    if os.path.exists(folder_path):\n",
    "        shutil.rmtree(folder_path)\n",
    "        print(f'Folder {folder_path} deleted')\n",
    "\n",
    "    os.makedirs(folder_path)\n",
    "    print(f'Folder {folder_path} created')\n",
    "    return folder_path\n",
    "\n",
    "\n",
    "def capture_images(class_name, num_images, capture_time, img_size, box_size, save_path):\n",
    "    if sys.platform == 'darwin':\n",
    "        cap = cv2.VideoCapture(0, cv2.CAP_AVFOUNDATION)\n",
    "    else:\n",
    "        cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print('Cannot open camera')\n",
    "        return False\n",
    "\n",
    "\n",
    "    capture_interval = capture_time / num_images\n",
    "\n",
    "    print(f'\\n=== Capturing {class_name.upper()} ===')\n",
    "    print(f'position yourself in {class_name.upper()} and press SPACE to start!')\n",
    "    print('Press Q to quit')\n",
    "\n",
    "    window_name = 'Capture Images'\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "\n",
    "            frame - cv2.flip(frame, 1)  #flip image to better position\n",
    "\n",
    "            #add instructions in the screen\n",
    "            cv2.putText(frame, f'Position yourself in {class_name.upper()}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7,\n",
    "                        (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'Press SPACE to start', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "            #draw the capture area\n",
    "            h, w = frame.shape[:2]\n",
    "            cx, cy = w // 2, h // 2\n",
    "            cv2.rectangle(frame, (cx - box_size // 2, cy - box_size // 2),\n",
    "                          (cx + box_size // 2, cy + box_size // 2), (0, 255, 0), 2)\n",
    "\n",
    "            cv2.imshow(window_name, frame)\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord(' '):\n",
    "                break\n",
    "            elif key == ord('q'):\n",
    "                cap.release()\n",
    "                cv2.destroyWindow(window_name)\n",
    "                cv2.waitKey(1)\n",
    "                return False\n",
    "\n",
    "        #start capture with countdown\n",
    "        start_time = time.time()\n",
    "        images_captured = 0\n",
    "        last_capture_time = 0\n",
    "\n",
    "        while images_captured < num_images:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            #mirrors the image\n",
    "            frame = cv2.flip(frame, 1)\n",
    "\n",
    "            elapsed_time = time.time() - start_time\n",
    "            remaining_time = max(0, capture_time - elapsed_time)\n",
    "\n",
    "            #draw the capture area\n",
    "            h, w = frame.shape[:2]\n",
    "            cx, cy = w // 2, h // 2\n",
    "            cv2.rectangle(frame, (cx - box_size // 2, cy - box_size // 2),\n",
    "                          (cx + box_size // 2, cy + box_size // 2), (0, 0, 255), 2)\n",
    "\n",
    "            #add the time countdown and photo capture count\n",
    "            cv2.putText(frame, f'Tempo: {remaining_time:.1f}s', (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            cv2.putText(frame, f'Fotos: {images_captured}/{num_images}', (10, 60),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            cv2.putText(frame, f'{class_name.upper()}', (10, 90),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "            cv2.imshow(window_name, frame)\n",
    "\n",
    "            if elapsed_time - last_capture_time >= capture_time:\n",
    "                #extract the region os interest\n",
    "                roi = frame[cy - box_size // 2:cy + box_size // 2,\n",
    "                cx - box_size // 2:cx + box_size // 2]\n",
    "\n",
    "                #convert to gray_scale\n",
    "                roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                #resize to desired size\n",
    "                roi_resized = cv2.resize(roi_gray, (img_size, img_size))\n",
    "\n",
    "                #save image\n",
    "                filename = os.path.join(save_path, f'{class_name}_{images_captured + 1:03d}.png')\n",
    "                cv2.imwrite(filename, roi_resized)\n",
    "\n",
    "                images_captured += 1\n",
    "                last_capture_time = elapsed_time\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "            if elapsed_time >= capture_time and images_captured >= num_images:\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        #release camera and close the window\n",
    "        cap.release()\n",
    "        cv2.destroyWindow(window_name)\n",
    "\n",
    "        for _ in range(10):\n",
    "            cv2.waitKey(1)\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    print(f'{images_captured} images for {class_name.upper()} captured')\n",
    "    return True"
   ],
   "id": "ee3ec2d86d23562e",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.2. Image capture",
   "id": "52aae588b2a4ae5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T14:49:54.924142500Z",
     "start_time": "2025-12-21T14:49:46.286333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if new_capture:\n",
    "    capture_path = prepare_capture_folder()\n",
    "\n",
    "    print('\\n=== Capture Images ===')\n",
    "    print(f'Time per class: {capture_time} seconds')\n",
    "    print(f'Photos per class: {capture_count}')\n",
    "    print(f'Capture area: {img_size} x {img_size} pixels')\n",
    "    print(f'Capture area: {box_size} x {box_size} pixels')\n",
    "    print('=' * 20)\n",
    "\n",
    "    #capture per class\n",
    "    for class_name in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S',\n",
    "                       'T', 'U', 'V', 'W', 'X', 'Y', 'Z']:\n",
    "        success = capture_images(class_name, capture_count, capture_time, img_size, box_size, capture_path)\n",
    "        if not success:\n",
    "            print(f'The class {class_name.upper()} not captured')\n",
    "            break\n",
    "        time.sleep(1)\n",
    "\n",
    "    print('\\n=== Capture finished ===')\n",
    "\n",
    "else:\n",
    "    capture_path = os.path.join('data', 'capture')\n",
    "    if os.path.exists(capture_path):\n",
    "        print(f'Using existent dataset: {capture_path}')\n",
    "    else:\n",
    "        print(f'Erorr: {capture_path} does not exist')\n",
    "        print('Define new_capture as True to create a new dataset')"
   ],
   "id": "dc6057271c25addf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder dataset\\capture deleted\n",
      "Folder dataset\\capture created\n",
      "\n",
      "=== Capture Images ===\n",
      "Time per class: 10 seconds\n",
      "Photos per class: 50\n",
      "Capture area: 128 x 128 pixels\n",
      "Capture area: 400 x 400 pixels\n",
      "====================\n",
      "\n",
      "=== Capturing A ===\n",
      "position yourself in A and press SPACE to start!\n",
      "Press Q to quit\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:1261: error: (-27:Null pointer) NULL window: 'Capture Images' in function 'cvDestroyWindow'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31merror\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 14\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m#capture per class\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m class_name \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mA\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mB\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mD\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mF\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mG\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mH\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mI\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mJ\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mK\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mL\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mM\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mN\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mO\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mP\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mQ\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mR\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mS\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     13\u001B[0m                    \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mU\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mV\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mW\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mY\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mZ\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[1;32m---> 14\u001B[0m     success \u001B[38;5;241m=\u001B[39m \u001B[43mcapture_images\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclass_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcapture_count\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcapture_time\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimg_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbox_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcapture_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m success:\n\u001B[0;32m     16\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclass_name\u001B[38;5;241m.\u001B[39mupper()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not captured\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[1;32mIn[17], line 122\u001B[0m, in \u001B[0;36mcapture_images\u001B[1;34m(class_name, num_images, capture_time, img_size, box_size, save_path)\u001B[0m\n\u001B[0;32m    119\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    120\u001B[0m     \u001B[38;5;66;03m#release camera and close the window\u001B[39;00m\n\u001B[0;32m    121\u001B[0m     cap\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m--> 122\u001B[0m     \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdestroyWindow\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwindow_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    124\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m10\u001B[39m):\n\u001B[0;32m    125\u001B[0m         cv2\u001B[38;5;241m.\u001B[39mwaitKey(\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[1;31merror\u001B[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:1261: error: (-27:Null pointer) NULL window: 'Capture Images' in function 'cvDestroyWindow'\n"
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
